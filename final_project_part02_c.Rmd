---
title: "final_project_part02_c"
author: "I-Ling Yeh"
date: "2020/11/2"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages

```{r, load_packages}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(visdat)
library(corrplot)
```

## Final project data

Reads in the data for the final project.  

```{r, read_glimpse_data}
data_url <- 'https://raw.githubusercontent.com/jyurko/INFSCI_2595_Fall_2020/master/HW/final_project/infsci_2595_final_project_data.csv'

df <- readr::read_csv(data_url, col_names = TRUE)
```

## Model training: Regression models-C

Separate the variables associated with Step 1 in Option B.  

```{r, make_step_1_data}
step_1_df <- df %>% select(xA, xB, x01:x06, response_1) %>% 
  mutate(xA = factor(xA),
         xB = factor(xB))
```

I will try out multiple candidate models, that is from simple to complex. These models are trained in `caret`. 

```{r, load_packages_b}
library(caret)
```

I will use 5-fold cross-validation with 3 repeats for this project.

```{r, resampling}
my_ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 3, savePredictions = TRUE)
```

I choose RMSE as my performance metric.

```{r, performance metric}
my_metric <- "RMSE"
```

### Linear models

Let's start out with a simple linear model, assuming linear additive terms for all inputs. Train and tune Linear additive model for providing a baseline comparison to the other models:

```{r, linear_model}
set.seed(2001)
mod_1 <- train(response_1 ~ .,
               data = step_1_df,
               method = "lm",
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl)

mod_1
```

Let's slowly start to increase the complexity by considering interaction terms.

```{r, check_design_matrix}
model.matrix(response_1 ~ (.)^3, data = step_1_df) %>% dim()
```

Because we have so many terms when we include interactions, let's use a regularized regression model. Train and tune regularized regression with Elastic net:

```{r, regularized_regression}
set.seed(2001)
mod_2_default <- train(response_1 ~ (.)^3,
               data = step_1_df,
               method = "glmnet",
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl)
mod_2_default
```

```{r, regularized_regression_tune}
enet_grid <- expand.grid(alpha = seq(0.1, 0.9, by = 0.1),
                         lambda = exp(seq(-6, -3, length.out = 15)))

set.seed(2001)
mod_2_tune <- train(response_1 ~ (.)^3,
               data = step_1_df,
               method = "glmnet",
               tuneGrid = enet_grid,
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl)
mod_2_tune
```
                         
```{r, regularized_regression_best_parameter}
ggplot(mod_2_tune) + theme_bw()
```

```{r, regularized_regression_best_parameterb}
mod_2_tune$bestTune
```

```{r, regularized_regression_coefficientb}
coef(mod_2_tune$finalModel) %>% rownames()
```

There are 114 non-zero features in regularized regression with Elastic net. 

```{r, regularized_regression_coefficient}
coef(mod_2_tune$finalModel, s = mod_2_tune$bestTune$lambda) %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  tibble::rownames_to_column("coef_name") %>% 
  tibble::as_tibble() %>% 
  purrr::set_names(c("coef_name", "coef_value")) %>% 
  filter(coef_value != 0) %>% 
  nrow()
```

Train and tune Partial Least Squares:

```{r, CART}
set.seed(2001)
mod_3 <- train(response_1 ~ .,
               data = step_1_df,
               method = "pls",
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl)
mod_3
```

### Non-linear models

Now let's try out some more complex models that can learn non-linear patterns in the data. Train and tune Neural network:

```{r, Neural_network}
set.seed(2001)
mod_4_default <- train(response_1 ~ .,
               data = step_1_df,
               method = "nnet",
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl,
               trace = FALSE,
               linout = TRUE)
mod_4_default
```

```{r, Neural_network_tune}
nnet_grid <- expand.grid(size = c(3, 5, 10, 15),
                         decay = exp(seq(-6, 3, length.out = 31)))

set.seed(2001)
mod_4_tune <- train(response_1 ~ .,
               data = step_1_df,
               method = "nnet",
               tuneGrid = nnet_grid,
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl,
               trace = FALSE,
               linout = TRUE)
mod_4_tune
```

```{r,Neural_network_best_parameter}
mod_4_tune$bestTune
```

```{r, Neural_network_plot}
plot(mod_4_tune, xTrans = log)
```

```{r, Neural_network_load}
library(NeuralNetTools)
```

```{r, Neural_network_netplot}
plotnet(mod_4_tune$finalModel)
```

Train and tune Random Forest:

```{r, random_forest_default}
set.seed(2001)
mod_5 <- train(response_1 ~ .,
                       data = step_1_df,
                       method = "rf",
                       metric = my_metric,
                       trControl = my_ctrl,
                       importance = TRUE)
mod_5
```

```{r, random_forest_plot}
plot(mod_5)
```


Train and tune boosted tree model with `xgboost`:

```{r, xgboost}
set.seed(2001)
mod_6 <- train(response_1 ~ .,
                       data = step_1_df,
                       method = "xgbTree",
                       metric = my_metric,
                       trControl = my_ctrl,
                       importance = TRUE)
mod_6
```

```{r,xgboost_best_parameter}
mod_6$bestTune
```

```{r, xgboost_plot}
plot(mod_6)
```

Train and tune SVM:

```{r, svm}
set.seed(2001)
mod_7 <- train(response_1 ~ .,
               data = step_1_df,
               method = "svmRadial",
               metric = my_metric,
               preProcess = c("center", "scale"),
               trControl = my_ctrl)
mod_7
```

### Compare models

Now we have fit all of the models, let's compare the cross-validation performance metrics.

```{r, regression_result}
regression_results = resamples(list(LM = mod_1,
                                    GLMNET_trips = mod_2_tune,
                                    PLS = mod_3,
                                    NNET = mod_4_tune,
                                    RF = mod_5,
                                    XGB = mod_6,
                                    SVM = mod_7))
```

Now we can visually compare the performance metrics.

```{r, performance_metrics}
dotplot(regression_results)
```

Zoom in to show RMSE:

```{r, rmse}
dotplot(regression_results, metric = "RMSE")
```

Zoom in to show R-squared:

```{r, rsquared}
dotplot(regression_results, metric = "Rsquared")
```

From the above, the random forest would be the best model. Let's now visualize the random forest hold-out set predictions compared to the observations.
 
```{r, fold_performance}
mod_5$pred %>% tibble::as_tibble() %>% 
  filter(mtry == mod_5$bestTune$mtry) %>% 
  tidyr::separate(Resample,
                  c("fold_id", "rep_id"),
                  sep = "\\.",
                  remove = FALSE) %>% 
  ggplot(mapping = aes(x = obs, y = pred)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0,
              color = "red", linetype = "dashed") +
  facet_grid(rep_id ~ fold_id, labeller = "label_both") +
  theme_bw()
```
 
Compare the random forest to regularized regression model.

```{r, fold_performanceb}
mod_2_tune$pred %>% tibble::as_tibble() %>% 
  filter(alpha == mod_2_tune$bestTune$alpha,
         lambda ==mod_2_tune$bestTune$lambda) %>% 
  tidyr::separate(Resample,
                  c("fold_id", "rep_id"),
                  sep = "\\.",
                  remove = FALSE) %>% 
  ggplot(mapping = aes(x = obs, y = pred)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0,
              color = "red", linetype = "dashed") +
  facet_grid(rep_id ~ fold_id, labeller = "label_both") +
  theme_bw()
```

Now, plot the variable importance rankings in random forest.

```{r, varuabke_importance}
plot(varImp(mod_5))
```

